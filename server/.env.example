# =============================================================================
# ENVIRONMENT (development | staging | production)
# development: Skips GCS upload and progress tracking
# staging/production: Full pipeline with uploads and tracking
# =============================================================================
ENVIRONMENT=development

# =============================================================================
# Gemini API Configuration
# In production: Uses LiteLLM proxy (injected by forge-sentinel)
# For local dev: Get direct API key from https://makersuite.google.com/app/apikey
# =============================================================================
GEMINI_API_KEY=your_gemini_api_key_here
# For LiteLLM: https://litellm.n1-research.com (no /v1 suffix)
# For direct Google: https://generativelanguage.googleapis.com
GOOGLE_GEMINI_BASE_URL=https://generativelanguage.googleapis.com
GOOGLE_GEMINI_MODEL=gemini-2.5-pro

# Model Selection for Different Pipeline Stages
# These models are used at different stages of the Realm generation process
# In production, these are injected by forge-sentinel
MARKDOWN_MODEL=gemini-2.5-flash
INTERMEDIATE_MODEL=gemini-3-pro-preview
HTML_MODEL=gemini-3-flash-preview
IMAGE_MODEL=imagen-3.0-generate-001

# Optional: Anthropic/Claude Configuration
# Only needed if using Claude models in your pipeline
ANTHROPIC_BASE_URL=https://api.anthropic.com
ANTHROPIC_AUTH_TOKEN=your_anthropic_api_key_here
CLAUDE_MODEL=claude-4.5-haiku

# Data Directory
# Directory for storing temporary data
DATA_DIRECTORY=data

# =============================================================================
# Job Runner Configuration (for K8s job mode via forge-sentinel)
# =============================================================================
USER_ID=your_user_id_here
CHR_ID=your_chr_id_here

# N1 API Configuration
N1_API_HEADER=N1-Api-Key
N1_API_KEY=your_n1_api_key_here
N1_API_BASE_URL=https://api.n1.care/

# GCS Configuration (optional in development, required in staging/production)
BUCKET_NAME=your_gcs_bucket
PROJECT_ID=your_gcp_project
GCS_SERVICE_ACCOUNT_JSON={"type":"service_account",...}

# Optional: Langfuse Observability Configuration
# For monitoring and debugging AI model interactions
LANGFUSE_SECRET_KEY=your_langfuse_secret_key
LANGFUSE_PUBLIC_KEY=your_langfuse_public_key
LANGFUSE_HOST=https://cloud.langfuse.com
OBSERVABILITY_ENABLED=false

# Server Configuration
# Port on which the server will listen
PORT=3000
