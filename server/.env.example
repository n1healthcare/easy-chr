# =============================================================================
# ENVIRONMENT (development | staging | production)
# development: Skips GCS upload and progress tracking
# staging/production: Full pipeline with uploads and tracking
# =============================================================================
ENVIRONMENT=development

# =============================================================================
# Gemini API Configuration
# In production: Uses LiteLLM proxy (injected by forge-sentinel)
# For local dev: Get direct API key from https://makersuite.google.com/app/apikey
# =============================================================================
GEMINI_API_KEY=your_gemini_api_key_here
# For LiteLLM: https://litellm.n1-research.com (no /v1 suffix)
# For direct Google: https://generativelanguage.googleapis.com
GOOGLE_GEMINI_BASE_URL=https://generativelanguage.googleapis.com
GOOGLE_GEMINI_MODEL=gemini-2.5-pro

# Model Selection for Different Pipeline Stages
# These models are used at different stages of the Realm generation process
# In production, these are injected by forge-sentinel
MARKDOWN_MODEL=gemini-2.5-flash
INTERMEDIATE_MODEL=gemini-3-pro-preview
HTML_MODEL=gemini-3-flash-preview
IMAGE_MODEL=imagen-3.0-generate-001

# Optional: Anthropic/Claude Configuration
# Only needed if using Claude models in your pipeline
ANTHROPIC_BASE_URL=https://api.anthropic.com
ANTHROPIC_AUTH_TOKEN=your_anthropic_api_key_here
CLAUDE_MODEL=claude-4.5-haiku

# Data Directory
# Directory for storing temporary data
DATA_DIRECTORY=data

# =============================================================================
# Job Runner Configuration (for K8s job mode via forge-sentinel)
# =============================================================================
USER_ID=your_user_id_here
CHR_ID=your_chr_id_here

# N1 API Configuration
N1_API_HEADER=N1-Api-Key
N1_API_KEY=your_n1_api_key_here
N1_API_BASE_URL=https://api.n1.care/

# =============================================================================
# Storage Configuration
# Supports: local (development), s3 (production), gcs (legacy)
# =============================================================================
STORAGE_PROVIDER=local

# S3 Configuration (when STORAGE_PROVIDER=s3)
# AWS credentials are optional - uses IAM/IRSA if not set
BUCKET_NAME=n1-bucket-name
AWS_REGION=us-east-2
# AWS_ACCESS_KEY_ID=your_access_key
# AWS_SECRET_ACCESS_KEY=your_secret_key

# GCS Configuration (when STORAGE_PROVIDER=gcs, legacy support)
PROJECT_ID=your_gcp_project
GCS_SERVICE_ACCOUNT_JSON={"type":"service_account",...}

# Local storage base directory (when STORAGE_PROVIDER=local)
# STORAGE_BASE_DIR=./storage

# Optional: Langfuse Observability Configuration
# For monitoring and debugging AI model interactions
LANGFUSE_SECRET_KEY=your_langfuse_secret_key
LANGFUSE_PUBLIC_KEY=your_langfuse_public_key
LANGFUSE_HOST=https://cloud.langfuse.com
OBSERVABILITY_ENABLED=false

# =============================================================================
# Feature Flags
# =============================================================================
# 3D Body Twin viewer with landing page hub (disabled by default)
ENABLE_BODY_TWIN=false

# Server Configuration
# Port on which the server will listen
PORT=3000
